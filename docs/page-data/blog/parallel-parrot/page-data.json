{"componentChunkName":"component---src-pages-blog-markdown-remark-frontmatter-slug-jsx","path":"/blog/parallel-parrot/","result":{"data":{"markdownRemark":{"html":"<p>Large Language Models (LLMs) have revolutionized task automation, yet scaling these\noperations poses challenges in efficiency and reliability.\nWe've developed <a href=\"https://pypi.org/project/parallel-parrot/\">parallel-parrot</a>\n, a Python package that parallelizes LLM tasks to boost performance and reliability.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 640px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/30ef27738ec8d9e4caf1a8dfa4d41264/c08c5/0002-gareth-davies-EGcfyDiUv58-unsplash.jpg\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 66.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAEE/8QAFgEBAQEAAAAAAAAAAAAAAAAAAwAB/9oADAMBAAIQAxAAAAHcRRqLf//EABQQAQAAAAAAAAAAAAAAAAAAACD/2gAIAQEAAQUCX//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABQQAQAAAAAAAAAAAAAAAAAAACD/2gAIAQEABj8CX//EABcQAQEBAQAAAAAAAAAAAAAAAAAREFH/2gAIAQEAAT8hcyIr/9oADAMBAAIAAwAAABDbD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABoQAQEBAAMBAAAAAAAAAAAAAAERACFBUTH/2gAIAQEAAT8QoIPeSqJDnc15MAbV8vWgR6Ph5lXf/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"flock of parrots\"\n        title=\"\"\n        src=\"/static/30ef27738ec8d9e4caf1a8dfa4d41264/c08c5/0002-gareth-davies-EGcfyDiUv58-unsplash.jpg\"\n        srcset=\"/static/30ef27738ec8d9e4caf1a8dfa4d41264/e07e9/0002-gareth-davies-EGcfyDiUv58-unsplash.jpg 200w,\n/static/30ef27738ec8d9e4caf1a8dfa4d41264/066f9/0002-gareth-davies-EGcfyDiUv58-unsplash.jpg 400w,\n/static/30ef27738ec8d9e4caf1a8dfa4d41264/c08c5/0002-gareth-davies-EGcfyDiUv58-unsplash.jpg 640w\"\n        sizes=\"(max-width: 640px) 100vw, 640px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p><em>Photo by <a href=\"https://unsplash.com/@gdfoto?utm_source=unsplash&#x26;utm_medium=referral&#x26;utm_content=creditCopyText\">Gareth Davies</a>\non <a href=\"https://unsplash.com/photos/EGcfyDiUv58?utm_source=unsplash&#x26;utm_medium=referral&#x26;utm_content=creditCopyText\">Unsplash</a></em></p>\n<h3>Task Automation with Prompt Templates</h3>\n<p>To instruct the LLM about the task we wish to perform, we use prompt templates\ndeveloped using <a href=\"https://www.promptingguide.ai/\">prompt engineering</a></p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 771px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/41c32855f619537dd9750e340a44de23/5d030/0002-parallel-parrot-1.drawio.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 34%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABD0lEQVR42p2QbU/CMBSF9/9/leInIeEDQQERUcfcpiBsa7t1fXnstpgYJZrY5CQ37XPPPb0ReAbBy6FhGVesdoLXouU/J/osXPBcPFeMFznj25yTMP299986PF8z/DT0Tgc3jXODgdZd7c7C3vu/E6p8hEwvsNUymBnKssRaG7pdMGiDTJDtYWsd5UFQ7AXVUfbpvbMD5wYucvIOJ1e4JkWqmiTZcSoEplqHQZeIdIQTa+pGc8iO3E9jFpMN21mCKOvArXpG5VdQb4nq/Rj1do1TDwipyLIUIWqsSmiLG/RxPtTGULxXPM5TNrOY3TJHySa8xT3TCZ11hlPk6ySkfApf+n1H3Q7bxvQy2p7d4QeAZR8Pb3yGCQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Using prompts with context\"\n        title=\"\"\n        src=\"/static/41c32855f619537dd9750e340a44de23/5d030/0002-parallel-parrot-1.drawio.png\"\n        srcset=\"/static/41c32855f619537dd9750e340a44de23/772e8/0002-parallel-parrot-1.drawio.png 200w,\n/static/41c32855f619537dd9750e340a44de23/e17e5/0002-parallel-parrot-1.drawio.png 400w,\n/static/41c32855f619537dd9750e340a44de23/5d030/0002-parallel-parrot-1.drawio.png 771w\"\n        sizes=\"(max-width: 771px) 100vw, 771px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>The idea is to design a prompt template that will take in an <code>input</code> and\n<code>context</code>, and use that to generate a text <code>prompt</code>.  This then gives the LLM the instructions it needs to generate the type of output desired.</p>\n<p>For example, to shorten long documents while keeping their meaning, design a prompt template like:</p>\n<pre><code>Generate a concise summary of the following document, using the context provided:\ncontext: ${context}\ndocument: ${document}\n</code></pre>\n<p>We then use <a href=\"https://peps.python.org/pep-0292/\">code</a> to replace <code>${context}</code> with each context and replace <code>${document}</code> with the text of each document being processed.\nThe same prompt template serves many purposes. From summarizing company blog posts, to making meeting notes easier to review.  And it does so while injecting appropriate business context.</p>\n<h3>Generating Data</h3>\n<p>We've found that as one gets to more advanced use-cases, that the outputs that you want from the LLM inevitably become more complicated.  For example:</p>\n<ul>\n<li>Using a long document to generate several \"Frequently Asked Questions\", in question and answer pairs</li>\n<li>Parsing a document for multiple topics, and infer the sentiment (POSITIVE, NEUTRAL, or NEGATIVE) of each topic</li>\n<li>Identifying corporate entities in a document, and the role for each of them in the document (vendor, client, etc)</li>\n</ul>\n<p>For this we can leverage two features provided by modern LLM APIs:</p>\n<ul>\n<li><strong>JSON-formatted outputs</strong>: Allows for easier parsing.  For OpenAI, this is the <a href=\"https://platform.openai.com/docs/guides/gpt/chat-completions-api\">\"function calling\"</a> feature</li>\n<li><strong>Multiple Choices</strong>:  Generate multiple different outputs for each request.  This can make it more likely that one of the outputs best matches the goal you are trying to achieve.  For OpenAI, this is specified by setting the number of choices (<code>n</code>) to be greater than one.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/84a2eb813711a925cd36d13bc953a1e2/024d6/0002-parallel-parrot-2.drawio.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 35.50000000000001%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABI0lEQVR42p2RWUvDUBSE8///kU9uqKRoQeyiTZWUGm2Sm3RJcrPc5fOmVnywIjhwXs4yM4fxOMBaCKKCwTRhEUt+wB7qGKwG04Lu8L56xi2n245I1JS15i90nXI31hmxxIFP/HCCEY94upwjxR26ClGqo22bg6r5rF7MGOqiQe5qjO57hrLYorVyNwrxPECMHGE6wTMyRO9G2OaVLMt4X6V0ZYSML6mFT1uvyZMdwXDB7DZknRSoYkq1OkcmN26+Yb0csZlfYfK5c+iGxdsFuphRSYmsG4yq0PU7pomdSedadsSLjFUoaKTCtiuy5TV55NNUgiy8J386c4QzPKtKdJNjHcl/0O1f9hHj/uXxdyjHI7W/Etl9IP2GJX0ZkkxOncOAD580HJaGPjSIAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Structured LLM output\"\n        title=\"\"\n        src=\"/static/84a2eb813711a925cd36d13bc953a1e2/5a190/0002-parallel-parrot-2.drawio.png\"\n        srcset=\"/static/84a2eb813711a925cd36d13bc953a1e2/772e8/0002-parallel-parrot-2.drawio.png 200w,\n/static/84a2eb813711a925cd36d13bc953a1e2/e17e5/0002-parallel-parrot-2.drawio.png 400w,\n/static/84a2eb813711a925cd36d13bc953a1e2/5a190/0002-parallel-parrot-2.drawio.png 800w,\n/static/84a2eb813711a925cd36d13bc953a1e2/024d6/0002-parallel-parrot-2.drawio.png 961w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p>For example, say we use the prompt template:</p>\n<pre><code>Generate question and answer pairs from the following document.\nOutput a list of JSON objects with keys \"question\" and \"answer\".\nOnly output questions and answers clearly described in the document.\ndocument: ${text}\n</code></pre>\n<p>This could turn a <a href=\"https://en.wikipedia.org/wiki/George_Washington\">wikipedia page about George Washington</a> into a list of question and answer pairs:</p>\n<pre><code class=\"language-json\">[\n  {\n    \"question\": \"Who was the first president of the United States?\",\n    \"answer\": \"George Washington\"\n  },\n  {\n    \"question\": \"What position did George Washington hold during the American Revolutionary War?\",\n    \"answer\": \"Commander of the Continental Army\"\n  },\n  {\n    \"question\": \"What document did George Washington help draft and ratify?\",\n    \"answer\": \"The Constitution of the United States\"\n  },\n]\n</code></pre>\n<p>These question and answer pairs could then be used to:</p>\n<ul>\n<li>Create a new document of \"Frequenty Asked Questions\"</li>\n<li>Make the content easier to skim for a reader</li>\n<li>Improve search database matches.  User questions typically match more closely to LLM generated questions than to original documents.</li>\n</ul>\n<h3>Scale</h3>\n<p>The above is powerful, but it starts to get tricky when you try to scale to thousands of tasks.  Processing a thousand documents one after the other (in series) could take over 8 hours.  And if there is an API or network error near the end, it could for you to start all over.</p>\n<p>To address this, we created a python package: <a href=\"https://pypi.org/project/parallel-parrot/\">parallel-parrot</a> which makes LLM calls in parallel.  It deals with all the issues related to concurrency, retries, API throttling, and other low-level concerns.  Parallelization reduces the total time for processing a thousand documents from hours to minutes.</p>\n<p>Series vs Parallel:\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/4fbe519297091b642d57104b0df7bd8a/c9156/0002-parallel-parrot-3.drawio.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 55.49999999999999%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABEElEQVR42qWSbWuEMBCE/f8/r6VQ7kvp6b3Q07ibxOiZ6HQ8vR4tFloUFuOTcZhNNgshQNTCsbo2oHMVmqaBY13bFm1oyAwC385zfWf+we66liyzZg+rJaQS1JcCUjzBLawua7IcWjzDSwGVC5mZdTl1db6wRXd4QTYOA4aU0PcRw5CQYofE75TIuXdb9+GLzZUQrxOL31i6tsj6GOFDh6n1lEYaRmx5MmfyR8vlHBvj8EM2rvy6zjK1wksReOfgbA1X7lcM/5HQy5FGBmoEWh1hz7tthqpTQmVCz9Yr2I93Go4bzlAOUBoJE0rJ0TjtfjmfvybkHE2D7S0TimHCt20tN3qmWXlLqNUB9vS6yfAT6g1dXiKWTIYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Series vs Parallel\"\n        title=\"\"\n        src=\"/static/4fbe519297091b642d57104b0df7bd8a/5a190/0002-parallel-parrot-3.drawio.png\"\n        srcset=\"/static/4fbe519297091b642d57104b0df7bd8a/772e8/0002-parallel-parrot-3.drawio.png 200w,\n/static/4fbe519297091b642d57104b0df7bd8a/e17e5/0002-parallel-parrot-3.drawio.png 400w,\n/static/4fbe519297091b642d57104b0df7bd8a/5a190/0002-parallel-parrot-3.drawio.png 800w,\n/static/4fbe519297091b642d57104b0df7bd8a/c1b63/0002-parallel-parrot-3.drawio.png 1200w,\n/static/4fbe519297091b642d57104b0df7bd8a/29007/0002-parallel-parrot-3.drawio.png 1600w,\n/static/4fbe519297091b642d57104b0df7bd8a/c9156/0002-parallel-parrot-3.drawio.png 3971w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<p><a href=\"https://pypi.org/project/parallel-parrot/\">parallel-parrot</a> automatically:</p>\n<ul>\n<li>Takes in a pandas dataframe or native Python list of dictionaries</li>\n<li>Applies a prompt template to create a prompt per row</li>\n<li>Queries an API-based LLM in parallel, handling automatic retries and rate limiting</li>\n<li>Parses and dedupes the outputs from multiple choices, and from JSON outputs</li>\n<li>Outputs clean (<a href=\"https://towardsdatascience.com/why-and-how-to-explode-a-list-like-column-to-rows-in-pandas-b69c3391c01c/\">exploded</a> / <a href=\"https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html\">tidy</a> ) data in the original format</li>\n</ul>\n<p>For example, it can take in multiple rows of input data:</p>\n<pre><code class=\"language-json\">[\n    {\n        \"text\": \"George Washington (February 22, 1732 - December 14, 1799) was ...\",\n        \"source_url\": \"https://en.wikipedia.org/wiki/George_Washington\",\n    },\n    {\n        \"text\": \"John Adams (October 30, 1735 - July 4, 1826) was ...\",\n        \"source_url\": \"https://en.wikipedia.org/wiki/John_Adams\",\n    },\n]\n\n</code></pre>\n<p>Then use a few lines of Python:</p>\n<pre><code class=\"language-python\">import parallel_parrot as pp\n\nconfig = pp.OpenAIChatCompletionConfig(\n    openai_api_key=\"*your API key*\",\n    n=3,\n    system_message=\"you are a very precise assistant\",\n)\n\n(output, usage_stats) = pp.run_async(\n    pp.parallel_data_generation(\n        config=config,\n        input_data=input_data,\n        prompt_template=\"\"\"\nGenerate question and answer pairs from the following document.\nOutput a list of JSON objects with keys \"question\" and \"answer\".\nOnly output questions and answers clearly described in the document.\nIf there are no questions and answers, output an empty list.\ndocument: ${text}\n        \"\"\",\n        output_key_names=[\"question\", \"answer\"]\n    )\n)\n</code></pre>\n<p>To generate useful question and answer pairs:</p>\n<pre><code class=\"language-json\">[\n  {\n    \"text\": \"...\",\n    \"source_url\": \"https://en.wikipedia.org/wiki/George_Washington\",\n    \"question\": \"Who was the first president of the United States?\",\n    \"answer\": \"George Washington\"\n  },\n  {\n    \"text\": \"...\",\n    \"source_url\": \"https://en.wikipedia.org/wiki/George_Washington\",\n    \"question\": \"What position did George Washington hold during the American Revolutionary War?\",\n    \"answer\": \"Commander of the Continental Army\"\n  },\n  {\n    \"text\": \"...\",\n    \"source_url\": \"https://en.wikipedia.org/wiki/George_Washington\",\n    \"question\": \"What document did George Washington help draft and ratify?\",\n    \"answer\": \"The Constitution of the United States\"\n  },\n  {\n    \"text\": \"...\",\n    \"source_url\": \"https://en.wikipedia.org/wiki/John_Adams\",\n    \"question\": \"Who were some important contemporaries that John Adams corresponded with?\",\n    \"answer\": \"Adams regularly corresponded with important contemporaries, including his wife and adviser Abigail Adams and his friend and political rival Thomas Jefferson.\"\n  },\n  {\n    \"text\": \"...\",\n    \"source_url\": \"https://en.wikipedia.org/wiki/John_Adams\",\n    \"question\": \"Who was John Adams?\",\n    \"answer\": \"John Adams was an American statesman, attorney, diplomat, writer, and Founding Father.\"\n  },\n]\n</code></pre>\n<p>Under the hood, it uses the high-performance <a href=\"https://docs.aiohttp.org/en/stable/\">aiohttp</a> package.  And uses the efficient I/O library <a href=\"https://libuv.org/\">libuv</a> via <a href=\"https://github.com/MagicStack/uvloop\">uvloop</a>.  It also uses best practices such as exponential backoff with jitter to deal with connection timeouts and retries.</p>\n<p>Depending on the API-based LLM you are using, some require time to \"warm up\" machines in the cloud.  Other APIs like OpenAI have <a href=\"https://platform.openai.com/docs/guides/rate-limits/rate-limits-in-headers\">rate limits</a> which can vary depending on account tier.  The package handles both of these by first making a \"setup\" request.  That request is used to configure and optimize the main parallel requests.  That same initial request also makes it easier to debug show-stopper issues like invalid credentials or API downtime.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \"\n    >\n      <a\n    class=\"gatsby-resp-image-link\"\n    href=\"/static/e8562bfe898be003877ce0156df6f210/455a8/0002-parallel-parrot-4.drawio.png\"\n    style=\"display: block\"\n    target=\"_blank\"\n    rel=\"noopener\"\n  >\n    <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 49.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABfklEQVR42oVSaWvcMBDd///PQmkpJORLmsRsElu2dVj3YUuv492Est3ACg+S0fDmHTrgxtq2hpg3TLMAYwO896gNWEtBa+2q//B12C//b9j/ox3AxgnOLfDGQasFZmGQx3ts2X01XgN+t06A5g1eTwh2hJwEFYeVr1i6X6jZXAPu9I2LmLmAEBwhhNN9rWfGMa0QOkDbgJQCQozwIcEqhq2kC3V7HZyZ0Y8SeuGQQtFOpUji+AetVmTHaJDAkVnIxZGHVMHDGANHfdtaLj108okAZgTTY+4VlrmHGB6hXu5OTIPuEOU9lGQ0bIQmFXwQxPCI6fkn7HzE+8eAruvQ9z0OJWcUSiyX7bSXdUOKJE+Puxisa0PyEwVCQ52G1RpaanjHIbrfyJqdLSDG+wu4GUpOCZOKsD6Th5E8TeRjoqA4yc0XgXym3L6DOn+tkuQX8Jnen34HZ5LkMrLlCer1B2oJ16HcYhicIHmG0rcky8FZCsNwqLcH1DX9I/DJ8C+KNQj54w9+8wAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"Setup request before batch\"\n        title=\"\"\n        src=\"/static/e8562bfe898be003877ce0156df6f210/5a190/0002-parallel-parrot-4.drawio.png\"\n        srcset=\"/static/e8562bfe898be003877ce0156df6f210/772e8/0002-parallel-parrot-4.drawio.png 200w,\n/static/e8562bfe898be003877ce0156df6f210/e17e5/0002-parallel-parrot-4.drawio.png 400w,\n/static/e8562bfe898be003877ce0156df6f210/5a190/0002-parallel-parrot-4.drawio.png 800w,\n/static/e8562bfe898be003877ce0156df6f210/c1b63/0002-parallel-parrot-4.drawio.png 1200w,\n/static/e8562bfe898be003877ce0156df6f210/29007/0002-parallel-parrot-4.drawio.png 1600w,\n/static/e8562bfe898be003877ce0156df6f210/455a8/0002-parallel-parrot-4.drawio.png 2781w\"\n        sizes=\"(max-width: 800px) 100vw, 800px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n  </a>\n    </span></p>\n<h3>Next Steps</h3>\n<p>We're open sourcing this <a href=\"https://github.com/novex-ai/parallel-parrot\">package</a> in the true spirit of open source: in the hopes that others find it useful as well.  Contributions and feedback are welcome, in the hopes that we can help each other unlock more of the value from this exciting new technology.</p>\n<p>Ready to implement Generative AI in your own company operations?  Contact us at\n<a href=\"https://novex.ai/\">Novex AI</a> to tailor an effective solution that fits your needs.</p>","frontmatter":{"date":"September 25, 2023","slug":"parallel-parrot","title":"Accelerating LLM operations with parallel-parrot","og_description":"Wrangling a flock of LLMs for speed, fun, and profit","og_image":"https://res.cloudinary.com/dn7sohze7/image/upload/v1695421900/parallel-parrot/0002-gareth-davies-EGcfyDiUv58-unsplash.jpg"}}},"pageContext":{"id":"1f628048-986e-57a9-a7d6-274f163e8f55","frontmatter__slug":"parallel-parrot","__params":{"frontmatter__slug":"parallel-parrot"}}},"staticQueryHashes":["3649515864"],"slicesMap":{}}